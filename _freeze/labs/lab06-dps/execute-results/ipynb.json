{
  "hash": "ed32efffb8472b7593a0d045475bbbfc",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lab 6: Implementing Direct Policy Search\"\nauthor: \"ENGS 199.20\"\ndate: \"10/31/2025\"\npublished-title: \"Due Date:\"\nformat:\n    html:        \n        warning: true\n        error: true\n        code-fold: true\n    ipynb:\n        warning: true\n        error: true\nexecute: \n    echo: true\n    enabled: true\njupyter: engs199\nengine: jupyter\nsidebar: main\n---\n\n\n\n\n\n\n## Overview\nToday we're going to compare open loop intertemporal and closed loop (via direct policy search with a radial basis function) optimization. This lab replicates and adapts various analyses in Quinn, J.D., Reed, P.M., Keller, K. (2017). [Direct policy search for robust multi-objective management of deeply uncertain socio-ecological tipping points.](https://www.sciencedirect.com/science/article/pii/S1364815216302250) Environmental Modelling & Software 92, 125-141.\n\nToday's objectives:\n\n1. Learn about Pareto optimal strategies for the simple lake problem obtained using the open loop and closed loop approaches  \n2. Evaluate and explain the solution dynamics from various strategies from both approaches\n3. Calculate performance metrics for different strategies\n4. Demonstrate your conceptual understanding of dynamic planning and how it relates to robustness\n5. Describe how you could incorporate dynamic planning into your decision analysis\n\n## Lab Workflow\n\n### Repository Setup\nYou can call the repository `dps_lab/`. \n\nIf you need a reminder on how to set up your project directory and create a GitHub repository, check the workflow and directory structure from lab 2. \n\nYou can directly export these lab instructions as a `.ipynb` file (look at the top right of the page). I put this file file directly under my `dps_lab/` dps directory. If you organize your directory different, please update relative filepaths in the code below accordingly. \n\n### Environment Setup\nEnvironment wise, you can use the one we set up for the previous lab.\n\nBe sure to include instructions in your `README.md` about how others can prepare the computational environment to run your notebook. \n\n### Our Analysis\nMake sure your environment is set up and active to run the code cells below. \n\n#### Revised lake problem overview\nQuinn et al., (2017) share the general concept of our problem statement in Lab 4 but introduce a different representation of system dynamics, new planning objectives, and new policy search approaches. \n\nDue to ongoing economic activity, a town emits phosphorous into a shallow lake (with a concentration of $a_t$), which also receives non-point source runoff (concentration $y_t$) from the surrounding area. The concentration of the lake at time $t+1$ is given by\n$$X_{t+1} = X_t + a_t + y_t + \\frac{X_t^q}{1+X_t^q} - bX_t,$$\n\nwhere:\n\n| Parameter | Value |\n| :------: | :------ |\n| $a_t$ | point-source phosphorous concentration from the town |\n| $y_t$ | non-point-source phosphorous concentration |\n| $q$ | rate at which phosphorous is recycled from sediment |\n| $b$| rate at which phosphorous leaves the lake |\n\nand $X_0 = 0$, $y_t \\sim LogNormal(\\log(0.03), 0.25)$, $q=2.5$, and $b=0.4$.\n\nThe goal of the optimization is to meet several objectices:\n\n| Objective | Description | Preference |\n| :------: | :------ | :------: |\n| Economic Benefits | Discounted economic benefits, assumed proportional to discounted P emissions | Max |\n| Lake P Concentration | Measure of the lake quality, where lower P concentrations correspond to clearer lakes | Min |\n| Policy Inertia | Measure of the stability of the control policy, where stable policies are favored | Max |\n| Reliability | Percentage of simulations that the lake P concentration is below the critical P threshold | Max |\n\nPlease consult Section 3.1 of the paper to see the mathematical formulation of the objectives.\n\n#### Non-linear dynamics in the shallow lake problem\nLet's take a closer look at the non-linear dynamics of the shallow lake problem. \n\nEach time step, the P concentration in the lake changes due to a natural inflow (+), an anthropogenic contribution (+), P recycled from sediments (+), and losses of P through outflow or sediment absorption (-). The critical P threshold exists where natural P recycling exceeds natural P losses as a function of the current P level in the lake. The paper has this helpful figure that illustrates the dynamics and critical P thresholds as a function of changing parameter values that determine natural recycling and loss rates. \n\n![](../_assets/img/quinn_nonlinear.jpg)\n\nAs posed in this and related studies, b & q are deeply uncertain parameters. In a given state of the world, we can calculate critical P by finding the roots (the values of X that make the equation equal to 0) of: $\\frac{X_t^q}{1+X_t^q} - bX_t$. \n\nThe intertemporal apporach will test out many possible combinations of $a_t$ over 100 years. With enough training, this approach could find the sequences of $a_t$ that are Pareto optimal and avoid the critical P threshold of the considered SOW. However, keep in mind that there are 100 decision variables! With $.01 < a_t < .1, \\forall t$, there are an infeasible number of candidate solutions to test. \n\nIn contrast, by using direct policy search with radial basis functions, we completely transform the decision space. Following Section 3.2.2, we now represent the decision levers as:\n$$\na_{t, i} = \\min(\\max(\\sum_{j=1}^n w_j |\\frac{X_{t,i} - c_j}{r_j}|^3, 0.01),0.1) \\quad \\forall {t, i}\n$$\n\nThis is a cubic radial basis function that parameterizes how to map P concentrations to P release decisions. $c_j$, $r_j$ and $w_j$ are the centers, radii, and weights of *n* cubic radial basis functions. The decision variables are these $3*n$ parameters, rather than the *T* decision variables in the intertemporal optimization. The authors used 2 radial basis functions in this study, so the DPS and intertemporal approaches consider 6 vs. 100 decision variables, respectively. The authors emphasize -- and this is important! -- that with the DPS approach, different P release decisions can be made in each of the N simulations (note the *i* indexing) because the decisions are informed by the lake P concentrations in a time step. We are searching for the values of $c_1$, $r_1$, $w_1$, $c_2$, $r_2$, and $w_2$. \n\nIn addition to evaluating open loop vs. closed loop strategies for their expected performance on objectives (and how robustly they do well on objectives across SOWs), we are going to pay close attention to how the various strategies act as the P level in the lake gets close to the critical P threshold in both the SOW the policy was trained on and in new SOWs.\n\n#### Comparing Intertemporal and DPS\nInstead of running the optimization (which takes a very long time), we are fortunate that we can directly use the reuslts from Quinn et al., (2017) due to their very well-formatted [repository](https://github.com/julianneq/Lake_Problem_DPS). Download the repo, which you can do [here](https://codeload.github.com/julianneq/Lake_Problem_DPS/zip/refs/heads/master), and extract the data from the `DataInPaper` subdirectory. I created a subdirectory called `data` which is at the same level in the lab directory as my `.ipynb` file. I put all the contents of `DataInPaper` into `data`. \n\nTo help build intuition about how the optimization works, we'll break down the process a bit. \n\nFirt, let's orient ourselves to the state of the world the optimization takes place in. \n\n::: {#69a170ba .cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\"}\nimport math\nimport numpy as np\n\n# Lake model parameters, number of years simulated, and number of samples generated\nq = 2\nb = 0.42\nalpha = 0.4\ndelta = 0.98\nmu = 0.03\nsigma = np.sqrt(10**(-5.0))\nlake0 = 0\nnYears = 100\nnSamples = 100\n```\n:::\n\n\nWe can find the critical P threshold by identifying the value of X at which the natural P recycling and losses are equal to each other:  $\\frac{X^q}{1+X^q} - bX = 0$ -> $\\frac{X^2}{1+X^2} - .42*X = 0$. There are several options to calculate this in python. We will use Brent's method as implemented in `scipy`. \n\n::: {#d1839b93 .cell execution_count=2}\n``` {.python .cell-code}\nfrom scipy.optimize import brentq\nimport matplotlib.pyplot as plt\n\nxs = np.arange(0, 2.5, 0.01)\n\ndef recycling(x, q=q):\n    return x**q / (1.0 + x**q)\n\ndef losses(x, b=b):\n    return b * x\n\nR = recycling(xs)\nL = losses(xs)\n\np_crit = brentq(lambda x: x**q / (1 + x**q) - b * x, 0.01, 1.5)\n\nfig, ax = plt.subplots(dpi=300)\nax.plot(xs, R, label=\"Recycling when q={}\".format(q), color=\"C0\")\nax.plot(xs, L, label=\"Losses when b={}\".format(b), color=\"C1\")\nax.axvline(p_crit, color=\"k\", linestyle=\"--\", alpha=0.8)\nax.scatter([p_crit], [recycling(p_crit)], color=\"red\", zorder=5, label=f\"Critical P = {p_crit:.3f}\")\nax.set_xlabel(\"P concentration\", size=12)\nax.set_ylabel(\"P Flux\", size=12)\nax.legend(fontsize='large')\n\nprint(f\"Critical P: {p_crit:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCritical P: 0.5445\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-3-output-2.png){}\n:::\n:::\n\n\nPay attention to the gap between losses and recycling in this state of the world to the left of the unstable equilibrium.   \n\nWhen we do intertemporal optimization, we are considering anthropogenic releases between 0.01 and 0.1 at each time step. Crucially, we are considering the full sequence of those releases over 100 time steps. In the MOEA framework, the optimization considers a candidate sequence of 100 releases and tests this against each simulation of natural inflows (because this is stochastic). The optimization looks for the candidate sequences that do \"best\" on the expected value of the multiple objectives. Then, it continues searching based on the EA design. \n\nLet's take a closer look at the intertemporal strategies highlighted in the paper that are best on the reliability and benefits objectives, respecitvely. \n\n::: {#c81dcd85 .cell execution_count=3}\n``` {.python .cell-code}\nimport scipy.stats as ss\n\n# Intertemporal lake problem\n# We set a seed for consistent results with the paper\n# We pass in the 100 actions for the strategy\ndef LakeModel_IT(seed, actions):\n    # Set inflow distribution parameters\n    log_std = np.sqrt(np.log(1+sigma**2/mu**2))\n    log_mu = np.log(mu) - 0.5*(log_std**2)\n    \n    # Initialize arrays to store P level in the lake at each time step\n    lake_state = np.zeros([nYears+1])\n\n    # Randomly generate nSamples of nYears of natural P inflows\n    natFlow = np.zeros([nYears])\n    np.random.seed(seed)\n    natFlow= np.exp(ss.norm.rvs(log_mu, log_std, nYears))\n    \n    # Run lake model simulation\n    lake_state[0] = lake0\n    for i in range(nYears):\n        lake_state[i+1] = lake_state[i]*(1-b) + (lake_state[i]**q)/(1+(lake_state[i]**q)) + actions[i] + natFlow[i]\n\n    # Return natural inflows and actions as well      \n    return (lake_state, natFlow, actions)\n\n# Load the intertemporal results\n\n# The rows are different strategies\n# The first 100 columns are the actions\n# The remaining columns are objective values, calculated\n# as expected values over the simulated natural inflows\n# The last column is the reliability objective\nIT = np.loadtxt('./data/Intertemporal/Intertemporal.resultfile')\n\n# The best reliability strategy minimizes the percentage of\n# simulations within a SOW where we pass critical P\nITmostRel = np.argmin(IT[:,103]) \n# The best benefits strategy maximizes net present value\nITmostBen = np.argmin(IT[:,100])\n\nyears = np.arange(nYears + 1)\n\nmostRel_states_all = []\nmostBen_states_all = []\n\nfig, ax = plt.subplots(figsize=(10, 6),\n                       dpi=300)\n\nfor sim in range(nSamples):\n    IT_states_mostRel = LakeModel_IT(sim, IT[ITmostRel, 0:100])\n    IT_states_mostBen = LakeModel_IT(sim, IT[ITmostBen, 0:100])\n    mostRel_states_all.append(IT_states_mostRel[0])\n    mostBen_states_all.append(IT_states_mostBen[0])\n    \n    # Plot total P time series with low alpha for clarity\n    ax.plot(years, IT_states_mostRel[0], color='tab:green', alpha=0.01)\n    ax.plot(years, IT_states_mostBen[0], color='tab:green', alpha=0.01)\n\n# Plot mean total P for both strategies\nax.plot(years, np.array(mostRel_states_all).mean(axis=0), color='tab:green', lw=2, ls='-')\nax.plot(years, np.array(mostBen_states_all).mean(axis=0), color='tab:green', ls='--', lw=2)\n\n# Plot actions (anthropogenic emissions) for both strategies\nax.plot(years[:-1], IT_states_mostRel[2], color='tab:blue', lw=2, ls='-')\nax.plot(years[:-1], IT_states_mostBen[2], color='tab:blue', lw=2, ls='--')\n\n# Critical phosphorus concentration line\nax.axhline(p_crit, color='red', ls='-.', label='Critical P (threshold)')\n\n# Labels and title\nax.set_xlabel('Year', size=12)\nax.set_ylabel('Phosphorus concentration / Emission flow', size=12)\nax.set_ylim([0, 1])\n\n# Custom legend\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Patch\n\nlegend_elements = [Line2D([0], [0], color='gray', lw=2, ls='-', label='Best Reliability Strategy'),\n                   Line2D([0], [0], color='gray', lw=2, ls='--', label='Best Benefits Strategy'),\n                   Patch(facecolor='tab:blue', edgecolor='tab:blue',\n                         label='Anthropogenic P'),\n                   Patch(facecolor='tab:green', edgecolor='tab:green',\n                         label='Total P'),\n                   Line2D([0], [0], color='red', lw=2, ls='-.', label='Critical P'),]\n\nax.legend(handles=legend_elements,\n          loc='upper left',\n          fontsize='large')\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-4-output-1.png){}\n:::\n:::\n\n\nNote that in order to see the anthropogenic P lines, I clipped the upper y limit, which goes well above 1 for Total P in the best benefits strategy case! \n\nBoth strategies are assessed over identical natural P inflow realizations. What do you recognize about the different strategy behaviors? \n\nAs an exercise, add subplots the P Flux from the natural P recycling and losses for each strategy across each realization. What do you notice about how the best benefits strategy manages the non-linear dynamics past the critical P threshold? Check equations 6-9 in the paper, which describe the intertemporal optimizaton, and explain how mathematical formulation choices influence the dynamics of the best benefits strategy. (Hint: consider constraints and the time horizon). \n\nNow, let's take a look at the analagous policies the authors found with direct policy search. We'll look at the state-action mappings from each as well as how that plays out over time. \n\nTo start, we'll plot the best reliability and benefits strategies:\n\n::: {#1601ab5d .cell execution_count=4}\n``` {.python .cell-code}\nimport seaborn as sns\nimport pandas as pd\n\n# Getting the actions from a given DPS parameterization\ndef DPSpolicy(lake_state, vars):\n    # Determine centers, radii and weights of RBFs\n    C = vars[0::3]\n    B = vars[1::3]\n    W = vars[2::3]\n    newW = np.zeros(len(W))\n    \n    # Normalize weights to sum to 1\n    total = sum(W)\n    if total != 0.0:\n        for i in range(len(W)):\n            newW[i] = W[i]/total\n    else:\n        for i in range(len(W)):\n            newW[i] = 1/n\n    \n    # Determine pollution emission decision, Y\n    Y = 0\n    for i in range(len(C)):\n        if B[i] != 0:\n            Y = Y + W[i]*((np.absolute(lake_state-C[i])/B[i])**3)\n            \n    Y = min(0.1,max(Y,0.01))\n    \n    return Y\n\n# Load the intertemporal results\n\n# The rows are different strategies\n# The first 100 columns are the actions\n# The remaining columns are objective values, calculated\n# as expected values over the simulated natural inflows\n# The last column is the reliability objective\nDPS = np.loadtxt('./data/DPS/DPS.resultfile')\n\n# The best reliability strategy minimizes the percentage of\n# simulations within a SOW where we pass critical P\n# There are only 6 decision variables so the \n# reliability objective is in the 10th column (index 9)\nDPSmostRel = np.argmin(DPS[:,9]) \n# The best benefits strategy maximizes net present value\nDPSmostBen = np.argmin(DPS[:,6])\n\n# Get the policy curves from the solutions\nlake_states = np.arange(0, 2.5, 0.01)\n\nrbf_list = []\nfor pol, var in zip(['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)'], [DPSmostRel, DPSmostBen, 26]):\n    rbf = pd.DataFrame()\n    rbf['Lake P'] = pd.Series(lake_states)\n    rbf['Anthropogenic P'] = rbf['Lake P'].apply(lambda x: DPSpolicy(x, DPS[var, 0:6]))\n    rbf['Strategy'] = pol\n    rbf_list.append(rbf)\n\nrbfs = pd.concat(rbf_list, axis=0)\n\nfig, ax = plt.subplots(figsize=(10, 5),\n                       dpi=300)\n\nsns.lineplot(data=rbfs, x='Lake P', y='Anthropogenic P', hue='Strategy', style='Strategy', ax=ax)\nax.set_xlim([0, 1])\n\nax.axvline(p_crit, color='red', ls='-.', lw=3, label='Critical P')\n\nax.legend(fontsize='large', loc='lower right')\nax.tick_params('both', labelsize=12)\nax.set_ylabel('Anthropogenic P', size=14)\nax.set_xlabel('Lake P', size=14)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nText(0.5, 0, 'Lake P')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-5-output-2.png){}\n:::\n:::\n\n\nIt turns out that many Pareto optimal strategies achieve the best reliability possible. We will consider an arbitrary strategy with the best reliability possible (blue) and the one used in the paper (green) for teaching purposes.\n\nLet's see what Lake P we take actions on based on a single stochastic realization of natural inflows with these various control policies. You can run this code with different seeds to see different results.  \n\n::: {#ac72e23c .cell execution_count=5}\n``` {.python .cell-code}\ndef LakeModel_DPS_adapted(seed, vars):\n    log_std = np.sqrt(np.log(1 + sigma**2 / mu**2))\n    log_mu = np.log(mu) - 0.5*(log_std**2)\n    \n    lake_state = np.zeros([nYears + 1])\n    np.random.seed(seed)\n    natFlow = np.exp(ss.norm.rvs(log_mu, log_std, nYears))\n    \n    recycling = np.zeros(nYears)  # Store recycling term at each step\n    loss = np.zeros(nYears)       # Store loss term (B * X_t) at each step\n    \n    lake_state[0] = lake0\n    Y = np.zeros(nYears)\n    Y[0] = DPSpolicy(lake_state[0], vars)\n    \n    for i in range(nYears):\n        recycling[i] = (lake_state[i]**q) / (1 + (lake_state[i]**q))\n        loss[i] = lake_state[i] * b  # assuming 'b' is the retention/loss factor\n        lake_state[i + 1] = lake_state[i] * (1 - b) + recycling[i] + Y[i] + natFlow[i]\n        if i < nYears - 1:\n            Y[i + 1] = DPSpolicy(lake_state[i + 1], vars)\n    \n    # Return lake_state, natural inflows, emissions, recycling, and loss arrays\n    return lake_state, natFlow, Y, recycling, loss\n\nseed = 100\n\nlake_state_rel, natFlow_rel, Y_rel, recycling_rel, loss_rel = LakeModel_DPS_adapted(seed, DPS[DPSmostRel, 0:6])\nlake_state_ben, natFlow_ben, Y_ben, recycling_ben, loss_ben = LakeModel_DPS_adapted(seed, DPS[DPSmostBen, 0:6])\nlake_state_paper, natFlow_paper, Y_paper, recycling_paper, loss_paper = LakeModel_DPS_adapted(seed, DPS[26, 0:6])\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\nnat_flows = [natFlow_rel, natFlow_ben, natFlow_paper]\nrec_flows = [recycling_rel, recycling_ben, recycling_paper]\nloss_flows = [loss_rel, loss_ben, loss_paper]\nemissions = [Y_rel, Y_ben, Y_paper]\nlake_states_list = [lake_state_rel, lake_state_ben, lake_state_paper]\n\n# Create figure with 3 columns and 3 rows: histograms above & below, curves in middle\nheight_ratios = [0.75, 1, 0.75]  # lake P hist, policy curve, natural inflows hist\n\nfig, axes = plt.subplots(3, 3, figsize=(8, 8), sharex='col', sharey='row',\n                         gridspec_kw={'height_ratios': height_ratios, 'hspace': 0.1})\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\n\n# Top row: Lake P histograms (less tall)\nfor i, ax in enumerate(axes[0]):\n    sns.histplot(lake_states_list[i], binwidth=.1, color='tab:blue', alpha=0.7, ax=ax)\n    ax.set_title(f\"{policies[i]}\", fontsize=12)\n    ax.set_ylabel('Lake P Histogram')\n    ax.tick_params(axis='x', labelbottom=False)  # hide x labels on top row\n    if i > 0:\n        ax.set_ylabel('')\n\n# Middle row: Control policy curves (taller)\nfor i, ax in enumerate(axes[1]):\n    df = rbf_list[i]\n    sns.lineplot(data=df, x='Lake P', y='Anthropogenic P', color='tab:green', ax=ax)\n    ax.axvline(p_crit, color='red', linestyle='--', lw=2, label='Critical P')\n    ax.set_ylabel('Anthropogenic P')\n    ax.tick_params(axis='x', labelbottom=False)\n    ax.legend(fontsize=9, loc='lower right')\n    if i > 0:\n        ax.set_ylabel('')\n\n# Bottom row: Natural inflows histograms (less tall)\nfor i, ax in enumerate(axes[2]):\n    sns.histplot(nat_flows[i] + rec_flows[i] + loss_flows[i], binwidth=.1, color='tab:orange', alpha=0.7, ax=ax)\n    ax.set_xlabel('P Concentration')\n    ax.set_ylabel('Non Anthropogenic P Histogram')\n    if i > 0:\n        ax.set_ylabel('')\n    \nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-6-output-1.png){}\n:::\n:::\n\n\nI intentionally chose a seed that leads to very high concentrations for the most benefits strategy. Check out a few other seeds. What seeds did you choose and do they produce the same patterns for each strategy? \n\nHere's an example with a different seed:\n\n::: {#9f276dfc .cell execution_count=6}\n``` {.python .cell-code}\nseed = 42\n\nlake_state_rel, natFlow_rel, Y_rel, recycling_rel, loss_rel = LakeModel_DPS_adapted(seed, DPS[DPSmostRel, 0:6])\nlake_state_ben, natFlow_ben, Y_ben, recycling_ben, loss_ben = LakeModel_DPS_adapted(seed, DPS[DPSmostBen, 0:6])\nlake_state_paper, natFlow_paper, Y_paper, recycling_paper, loss_paper = LakeModel_DPS_adapted(seed, DPS[26, 0:6])\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\nnat_flows = [natFlow_rel, natFlow_ben, natFlow_paper]\nrec_flows = [recycling_rel, recycling_ben, recycling_paper]\nloss_flows = [loss_rel, loss_ben, loss_paper]\nemissions = [Y_rel, Y_ben, Y_paper]\nlake_states_list = [lake_state_rel, lake_state_ben, lake_state_paper]\n\n# Create figure with 3 columns and 3 rows: histograms above & below, curves in middle\nheight_ratios = [0.75, 1, 0.75]  # lake P hist, policy curve, natural inflows hist\n\nfig, axes = plt.subplots(3, 3, figsize=(8, 8), sharex='col', sharey='row',\n                         gridspec_kw={'height_ratios': height_ratios, 'hspace': 0.1})\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\n\n# Top row: Lake P histograms (less tall)\nfor i, ax in enumerate(axes[0]):\n    sns.histplot(lake_states_list[i], binwidth=.1, color='tab:blue', alpha=0.7, ax=ax)\n    ax.set_title(f\"{policies[i]}\", fontsize=12)\n    ax.set_ylabel('Lake P Histogram')\n    ax.tick_params(axis='x', labelbottom=False)  # hide x labels on top row\n    if i > 0:\n        ax.set_ylabel('')\n\n# Middle row: Control policy curves (taller)\nfor i, ax in enumerate(axes[1]):\n    df = rbf_list[i]\n    sns.lineplot(data=df, x='Lake P', y='Anthropogenic P', color='tab:green', ax=ax)\n    ax.axvline(p_crit, color='red', linestyle='--', lw=2, label='Critical P')\n    ax.set_ylabel('Anthropogenic P')\n    ax.tick_params(axis='x', labelbottom=False)\n    ax.legend(fontsize=9, loc='lower right')\n    if i > 0:\n        ax.set_ylabel('')\n\n# Bottom row: Natural inflows histograms (less tall)\nfor i, ax in enumerate(axes[2]):\n    sns.histplot(nat_flows[i] + rec_flows[i] + loss_flows[i], binwidth=.1, color='tab:orange', alpha=0.7, ax=ax)\n    ax.set_xlabel('P Concentration')\n    ax.set_ylabel('Non Anthropogenic P Histogram')\n    if i > 0:\n        ax.set_ylabel('')\n    \nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-7-output-1.png){}\n:::\n:::\n\n\nWhat do you see about the distribution of all observed P concentrations across the realizations you evaluated of both naturally (inflows, recycling, loss summed on bottom row) and including the anthropogenic P concentration (top row)? \n\nNow, let's look across many stochastic realizations. \n\n::: {#91210b32 .cell execution_count=7}\n``` {.python .cell-code}\nseed = 100\n\nlake_state_rel, natFlow_rel, Y_rel, recycling_rel, loss_rel = LakeModel_DPS_adapted(seed, DPS[DPSmostRel, 0:6])\nlake_state_ben, natFlow_ben, Y_ben, recycling_ben, loss_ben = LakeModel_DPS_adapted(seed, DPS[DPSmostBen, 0:6])\nlake_state_paper, natFlow_paper, Y_paper, recycling_paper, loss_paper = LakeModel_DPS_adapted(seed, DPS[26, 0:6])\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\nnat_flows = [natFlow_rel, natFlow_ben, natFlow_paper]\nrec_flows = [recycling_rel, recycling_ben, recycling_paper]\nloss_flows = [loss_rel, loss_ben, loss_paper]\nemissions = [Y_rel, Y_ben, Y_paper]\nlake_states_list = [lake_state_rel, lake_state_ben, lake_state_paper]\n\n# Create figure with 3 columns and 3 rows: histograms above & below, curves in middle\nheight_ratios = [0.75, 1, 0.75]  # lake P hist, policy curve, natural inflows hist\n\nfig, axes = plt.subplots(3, 3, figsize=(8, 8), sharex='col', sharey='row',\n                         gridspec_kw={'height_ratios': height_ratios, 'hspace': 0.1})\n\npolicies = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\n\n# Top row: Lake P histograms (over all runs) - log scale y-axis\nfor i, ax in enumerate(axes[0]):\n    sns.histplot(lake_states_list[i], binwidth=.1, color='tab:blue', alpha=0.7, ax=ax)\n    ax.set_yscale('log') \n    ax.set_title(f\"{policies[i]}\", fontsize=12)\n    ax.set_ylabel('Lake P Histogram')\n    ax.set_xlim([0, 1])\n    ax.tick_params(axis='x', labelbottom=False)\n    if i > 0:\n        ax.set_ylabel('')\n\n# Middle row: Control policy curves (taller)\nfor i, ax in enumerate(axes[1]):\n    df = rbf_list[i]\n    sns.lineplot(data=df, x='Lake P', y='Anthropogenic P', color='tab:green', ax=ax)\n    ax.axvline(p_crit, color='red', linestyle='--', lw=2, label='Critical P')\n    ax.set_ylabel('Anthropogenic P')\n    ax.tick_params(axis='x', labelbottom=False)\n    ax.legend(fontsize=9, loc='lower right')\n    if i > 0:\n        ax.set_ylabel('')\n\n# Bottom row: Natural inflows histograms (less tall)\nfor i, ax in enumerate(axes[2]):\n    combined = nat_flows[i] + rec_flows[i] + loss_flows[i]\n    sns.histplot(combined, binwidth=.1, color='tab:orange', alpha=0.7, ax=ax)\n    ax.set_yscale('log')\n    ax.set_xlabel('P Concentration')\n    ax.set_ylabel('Non Anthropogenic P Histogram')\n    ax.set_xlim([0, 1])\n    if i > 0:\n        ax.set_ylabel('')\n    \nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-8-output-1.png){}\n:::\n:::\n\n\nWhat do you see about the distribution of all observed P concentrations across all the realizations of both naturally (inflows, recycling, loss summed on bottom row) and including the anthropogenic P concentration (top row)? \n\nLet's take a look at these P concentrations across all of these states. Each realization can have a different anthropogenic P sequence, so we're not going to plot exactly the same way we did for the intertemporal. \n\n::: {#8c4de15f .cell execution_count=8}\n``` {.python .cell-code}\npolicy_names = ['Most Reliable', 'Most Benefits', 'Most Reliable (From Paper)']\npolicy_indices = [DPSmostRel, DPSmostBen, 26]\n\n# Preallocate storage for states for all simulations and policies\nnSamples = 100  # your number of Monte Carlo simulations\nnYears = 100    # length of simulation\nyears = np.arange(nYears + 1)\n\ntotalP_all = {name: [] for name in policy_names}\nanthP_all = {name: [] for name in policy_names}\nnatP_all = {name: [] for name in policy_names}\nrecP_all = {name: [] for name in policy_names}\nlossP_all = {name: [] for name in policy_names}\n\n# Run all simulations for each policy\nfor sim in range(nSamples):\n    for name, idx in zip(policy_names, policy_indices):\n        lake_state, natFlow, actions, recs, losses = LakeModel_DPS_adapted(sim + 1000, DPS[idx, 0:6])\n        # collect total phosphorus time series (index 0 of returned tuple)\n        totalP_all[name].append(lake_state)\n        # collect anthro P time series\n        anthP_all[name].append(actions)\n        # collect the rest\n        natP_all[name].append(natFlow)\n        recP_all[name].append(recs)\n        lossP_all[name].append(losses)\n\n# Plotting setup\nfig, ax = plt.subplots(figsize=(12, 7), dpi=300)\n\ncolors = {'Most Reliable': 'tab:green',\n          'Most Benefits': 'tab:orange',\n          'Most Reliable (From Paper)': 'tab:purple'}\n\nlinestyles = {'Most Reliable': '-',\n              'Most Benefits': '--',\n              'Most Reliable (From Paper)': '-.'}\n\n# Plot individual simulation total P flows with very low alpha\nfor name in policy_names:\n    for run in totalP_all[name]:\n        ax.plot(years, run, color=colors[name], alpha=0.05)\n\n# Plot mean total P time series for each policy\nfor name in policy_names:\n    mean_totalP = np.mean(totalP_all[name], axis=0)\n    ax.plot(years, mean_totalP, color=colors[name], lw=2, linestyle=linestyles[name], label=f'{name} Mean Total P')\n\n# Plot critical phosphorus concentration line\nax.axhline(p_crit, color='red', linestyle='-.', lw=2, label='Critical P (threshold)')\n\n# Labels and limits\nax.set_xlabel('Year', fontsize=12)\nax.set_ylabel('Phosphorus concentration / Emission flow', fontsize=12)\nax.set_ylim([0, 1])\n\n# Construct a clear custom legend\nlegend_elements = [\n    Line2D([0], [0], color=colors['Most Reliable'], lw=2, ls=linestyles['Most Reliable'], label='Most Reliable Mean Total P'),\n    Line2D([0], [0], color=colors['Most Benefits'], lw=2, ls=linestyles['Most Benefits'], label='Most Benefits Mean Total P'),\n    Line2D([0], [0], color=colors['Most Reliable (From Paper)'], lw=2, ls=linestyles['Most Reliable (From Paper)'], label='Most Reliable (From Paper) Mean Total P'),\n    Line2D([0], [0], color='red', lw=2, ls='-.', label='Critical P (threshold)')\n]\nax.legend(handles=legend_elements, loc='upper right', fontsize='large')\n\nplt.title('Lake Phosphorus Concentrations and Emissions Across DPS Policies', fontsize=14)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-9-output-1.png){}\n:::\n:::\n\n\nHow would you characterize the behavior of the different strategies? Is the mean P a good way to characterize the strategies' dynamics? \n\nLet's take a closer look at those realizations where the max benefit policy leads to eutrophication. \n\n::: {#e3178f92 .cell execution_count=9}\n``` {.python .cell-code}\nfrom matplotlib.gridspec import GridSpec\n\ntemp = pd.DataFrame(totalP_all['Most Benefits'])\n# Runs that exceed critical P\neutrophic_runs_idx = temp[(temp > p_crit).sum(axis=1) > 0].index\nnon_eutrophic_runs_idx = temp[(temp > p_crit).sum(axis=1) == 0].index\n\n# Extract the eutrophic realizations data\ntotalP_eutrophic = [totalP_all['Most Benefits'][i] for i in eutrophic_runs_idx]\nanthP_eutrophic = [anthP_all['Most Benefits'][i] for i in eutrophic_runs_idx]\nnatFlow_eutrophic = [natP_all['Most Benefits'][i] for i in eutrophic_runs_idx]\nrecycling_eutrophic = [recP_all['Most Benefits'][i] for i in eutrophic_runs_idx]\nloss_eutrophic = [lossP_all['Most Benefits'][i] for i in eutrophic_runs_idx]\n\n# And non eutrophic\ntotalP_non_eutrophic = [totalP_all['Most Benefits'][i] for i in non_eutrophic_runs_idx]\nanthP_non_eutrophic = [anthP_all['Most Benefits'][i] for i in non_eutrophic_runs_idx]\nnatFlow_non_eutrophic = [natP_all['Most Benefits'][i] for i in non_eutrophic_runs_idx]\nrecycling_non_eutrophic = [recP_all['Most Benefits'][i] for i in non_eutrophic_runs_idx]\nloss_non_eutrophic = [lossP_all['Most Benefits'][i] for i in non_eutrophic_runs_idx]\n\nyears = np.arange(len(totalP_eutrophic[0]))\n\n# Net recycling/loss:\nnet_recycling_eutrophic = [r - l for r, l in zip(recycling_eutrophic, loss_eutrophic)]\n\nnet_recycling_non_eutrophic = [r - l for r, l in zip(recycling_non_eutrophic, loss_non_eutrophic)]\n\n# Combine and create figure\nfig = plt.figure(figsize=(10, 8), dpi=300)\ngs = GridSpec(nrows=2, ncols=2, figure=fig, width_ratios=[1, 1], wspace=0.1, hspace=0.25, \n              height_ratios=[.3, 1])\n\n# --- Top panel: RBF control policies ---\nax0 = fig.add_subplot(gs[0, :])\nsns.lineplot(data=rbfs[rbfs['Strategy'] == 'Most Benefits'], x='Lake P', y='Anthropogenic P', hue='Strategy', style='Strategy', ax=ax0)\nax0.axvline(p_crit, color='red', linestyle='-.', lw=3, label='Critical P')\nax0.set_title('RBF Control Policy - Most Benefits', size=14)\nax0.set_ylabel('Anthropogenic P')\nax0.set_xlabel('')\nax0.set_xlim([0, .6])\nax0.legend(fontsize='medium')\n\n# --- Bottom panel, Left: Dynamics of eutrophic runs ---\nax10 = fig.add_subplot(gs[1, 0])\nfor i in range(len(eutrophic_runs_idx)):\n    # Plot each realization with low alpha for clarity:\n    ax10.plot(years, totalP_eutrophic[i], color='tab:orange', alpha=0.1)\n    ax10.plot(years[:-1], anthP_eutrophic[i], color='tab:blue', alpha=0.1)\n    ax10.plot(years[:-1], natFlow_eutrophic[i], color='tab:green', alpha=0.1)\n    ax10.plot(years[:-1], net_recycling_eutrophic[i], color='tab:red', alpha=0.1)\n\n# Bottom panel, right: dynamics of non eutrophic runs\nax11 = fig.add_subplot(gs[1, 1])\nfor i in range(len(eutrophic_runs_idx)):\n    # Plot each realization with low alpha for clarity:\n    ax11.plot(years, totalP_non_eutrophic[i], color='tab:orange', alpha=0.1)\n    ax11.plot(years[:-1], anthP_non_eutrophic[i], color='tab:blue',  alpha=0.1)\n    ax11.plot(years[:-1], natFlow_non_eutrophic[i], color='tab:green', alpha=0.1)\n    ax11.plot(years[:-1], net_recycling_non_eutrophic[i], color='tab:red', alpha=0.1)\n\nax10.axhline(p_crit, color='black', linestyle='--', label='Critical P')\nax10.set_xlabel('Year')\nax10.set_ylabel('P concentration / flux')\nax10.set_title('Eutrophic Realizations')\nax10.set_xlim(0, 20)\nax10.set_ylim([-.1, .6])\n\nax11.plot(years, np.mean(totalP_non_eutrophic, axis=0), color='tab:orange', lw=2, label='Mean Total P')\nax11.plot(years[:-1], np.mean(anthP_non_eutrophic, axis=0), color='tab:blue', lw=2, label='Mean Anthropogenic P')\nax11.plot(years[:-1], np.mean(natFlow_non_eutrophic, axis=0), color='tab:green', lw=2, label='Mean Natural Inflow')\nax11.plot(years[:-1], np.mean(net_recycling_non_eutrophic, axis=0), color='tab:red', lw=2, label='Mean Net Recycling/Loss')\n\nax11.axhline(p_crit, color='black', linestyle='--', label='Critical P')\nax11.set_xlabel('Year')\nax11.set_ylabel('')\nax11.set_title('Non-Eutrophic Realizations')\nax11.legend(fontsize='medium')\nax11.set_xlim(0, 20)\nax11.set_ylim([-.1, .6])\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/d2/g0h08s551zb2hz_ws2g4ggh400hbd0/T/ipykernel_27944/1823386331.py:82: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-10-output-2.png){}\n:::\n:::\n\n\nCan you see what the difference is between the eutrophic and non-eutrophic realizations? Recall that these are using the exact same control policies. Let's try zooming in even more on the early years of the problem and focus on the total P trajectories, along with our RBF and where it tells us to emit less.  Recall that in our optimization formulation, we set .01 as our minimum allowable emission. \n\n::: {#18f7e0c4 .cell execution_count=10}\n``` {.python .cell-code}\n# Combine and create figure\nfig = plt.figure(figsize=(10, 8), dpi=300)\ngs = GridSpec(nrows=2, ncols=2, figure=fig, width_ratios=[1, 1], wspace=0.1, hspace=0.25, \n              height_ratios=[.3, 1])\n\n# --- Top panel: RBF control policies ---\nax0 = fig.add_subplot(gs[0, :])\nsns.lineplot(data=rbfs[rbfs['Strategy'] == 'Most Benefits'], x='Lake P', y='Anthropogenic P', hue='Strategy', style='Strategy', ax=ax0)\nax0.set_title('RBF Control Policy - Most Benefits', size=14)\nax0.set_ylabel('Anthropogenic P')\nax0.set_xlabel('')\nax0.set_xlim([.20, .32])\nax0.legend(fontsize='medium')\n\n# --- Bottom panel, Left: Dynamics of eutrophic runs ---\nax10 = fig.add_subplot(gs[1, 0])\nfor i in range(len(eutrophic_runs_idx)):\n    # Plot each realization with low alpha for clarity:\n    ax10.plot(years, totalP_eutrophic[i], color='tab:orange', alpha=0.1)\n    ax10.plot(years[:-1], anthP_eutrophic[i], color='tab:blue', alpha=0.1)\n    ax10.plot(years[:-1], natFlow_eutrophic[i], color='tab:green', alpha=0.1)\n    ax10.plot(years[:-1], net_recycling_eutrophic[i], color='tab:red', alpha=0.1)\n\n# Bottom panel, right: dynamics of non eutrophic runs\nax11 = fig.add_subplot(gs[1, 1])\nfor i in range(len(eutrophic_runs_idx)):\n    # Plot each realization with low alpha for clarity:\n    ax11.plot(years, totalP_non_eutrophic[i], color='tab:orange', alpha=0.1)\n    ax11.plot(years[:-1], anthP_non_eutrophic[i], color='tab:blue',  alpha=0.1)\n    ax11.plot(years[:-1], natFlow_non_eutrophic[i], color='tab:green', alpha=0.1)\n    ax11.plot(years[:-1], net_recycling_non_eutrophic[i], color='tab:red', alpha=0.1)\n\nax10.axhline(p_crit, color='black', linestyle='--', label='Critical P')\nax10.set_xlabel('Year')\nax10.set_ylabel('P concentration')\nax10.set_title('Eutrophic Realizations')\nax10.set_xlim(0, 5)\nax10.set_ylim([.20, .32])\n\nax11.plot(years, np.mean(totalP_non_eutrophic, axis=0), color='tab:orange', lw=2, label='Mean Total P')\n\nax11.set_xlabel('Year')\nax11.set_ylabel('')\nax11.set_title('Non-Eutrophic Realizations')\nax11.legend(fontsize='medium')\nax11.set_xlim(0, 5)\nax11.set_ylim([.20, .32])\nax11.tick_params(left=False, labelleft=False)\n\nax11.fill_between([0, 5], .24, .27, color='gray', alpha=.1)\nax10.fill_between([0, 5], .24, .27, color='gray', alpha=.1)\nax0.fill_between([.24, .27], 0, .1, color='gray', alpha=.1)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/d2/g0h08s551zb2hz_ws2g4ggh400hbd0/T/ipykernel_27944/1156415406.py:54: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-11-output-2.png){}\n:::\n:::\n\n\nWe can roughly highlight a region of P concentration at year 3 where the eutrophic and non-eutrophic realizations begin to look different from one another. The non-eutrophic realizations do not cross .27 in year 3, but many of the eutrophic realizations do. \n\nLet's revisit our P recycling and loss plot and zoom in on the area below the threshold. We'll add a shaded area to indicate the mean natural P inflow so that we can get a better sense for what P concentrations are dangerous. \n\n::: {#895e48cc .cell execution_count=11}\n``` {.python .cell-code}\nfig, ax = plt.subplots(dpi=300)\nax.plot(xs, R, label=\"Recycling when q={}\".format(q), color=\"C0\")\nax.plot(xs, L, label=\"Losses when b={}\".format(b), color=\"C1\")\n\nax.fill_between(xs, R, [r + .03 for r in R], label='Recycling + Mean P inflow (.03)', color='gray', alpha=.25)\nax.fill_between(xs, [r + .03 for r in R], [r + .04 for r in R], label='\"\" + small emission (.01)', color='green', alpha=.25)\n\nax.axvline(p_crit, color=\"k\", linestyle=\"--\", alpha=0.8)\nax.scatter([p_crit], [recycling(p_crit)], color=\"red\", zorder=5, label=f\"Critical P = {p_crit:.3f}\")\nax.set_xlabel(\"P concentration\", size=12)\nax.set_ylabel(\"P Flux\", size=12)\nax.set_xlim([0, .55])\nax.set_ylim([0, .25])\nax.legend(fontsize='large')\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-12-output-1.png){}\n:::\n:::\n\n\nThis plot suggests that even at relatively low P concentrations, the net P loss that occurs below the critical P threshold might be too low to support anthropogenic emissions that help us do well on our economic objective. For example, in between around .18 and .3, we see a very small margin of net loss. In some realizations, we might get unlucky and the variance in the natural P inflow will push us into net P gains at relatively low P concentrations. These P concentrations correspond to high emission actions for our max benefits policy, quickly taking us over the critical P threshold. \n\nNot that in the previous plot, the eutrophic realizations that were below .27 never lose enough P to avoid crossing the threshold (because we set our min P to .01). The interaction of emitting at least .01, along with the very small net loss at P concentrations at around .27 mean that a year with a large positive natural P (due to the variance) will be on its way to the critical P threshold with no turning back. Instead of a small emission, let's look at the same plot in terms of our max benefits and tw0 reliability policies. \n\n::: {#cf697f89 .cell execution_count=12}\n``` {.python .cell-code}\nfig, ax = plt.subplots(nrows=3, dpi=300, figsize=(8, 12), sharex=True)\n\nfor i, s_group in enumerate(rbfs.groupby(['Strategy'])):\n\n    ax[i].plot(xs, R, label=\"Recycling when q={}\".format(q), color=\"C0\")\n    ax[i].plot(xs, L, label=\"Losses when b={}\".format(b), color=\"C1\")\n\n    ax[i].fill_between(xs, R, [r + .03 for r in R], label='Recycling + Mean inflow', color='gray', alpha=.25)\n    ax[i].fill_between(xs, [r + .03 for r in R], s_group[1]['Anthropogenic P'].values + np.array(R), label='\"\" + Anthropogenic', color='green', alpha=.25)\n\n    ax[i].axvline(p_crit, color=\"k\", linestyle=\"--\", alpha=0.8)\n    ax[i].scatter([p_crit], [recycling(p_crit)], color=\"red\", zorder=5, label=f\"Critical P = {p_crit:.3f}\")\n    ax[i].set_ylabel(\"P Flux\", size=12)\n    ax[i].set_xlim([0, .55])\n    ax[i].set_ylim([0, .25])\n    ax[i].tick_params('both', labelsize=12)\n    ax[i].set_title(s_group[0][0] + \" Strategy\", size=12)\n    if i == 0:\n        ax[i].legend(fontsize='large', frameon=False)\n    if i == 2:\n        ax[i].set_xlabel(\"P concentration\", size=12)\n```\n\n::: {.cell-output .cell-output-display}\n![](lab06-dps_files/figure-ipynb/cell-13-output-1.png){}\n:::\n:::\n\n\nNote the P concentration where the most benefits strategy contributes its lowest emission. Do the non-eutrophic realizations ever cross this point?\n\n### Wrapping up lab\nIn today's lab, we scrutinized different strategies from the open loop and closed loop optimization approaches for how they manage the tipping point dynamics. To wrap up your lab, please include the following analysis and any visualizations that help you summarize your findings: \n\n1. Calculate performance metrics for the different strategies we reviewed (both the open loop and closed loop) over time across realizations.\n\n2. Calculate the robustness of the most benefits and most reliable strategies from the different optimization approaches to different SOWs using the same metric as in the paper. I encourage you to check the repository and to reproduce figure 8. Do it for intertemporal most reliability and most benefits. Then do it for closed loop most reliability (you can use either one we looked at - please be explicit) and most benefits. \n\n3. Considering your analysis from #1, our attention to dynamics in lab, and the results in Figure 11 in the paper, explain why the different optimization approaches (i.e., open vs. closed loop) lead to different robustness results. \n\n4. Considering #3, what would you consider for updating the policy search approach to improve robustness while still performing well on key objectives in the reference scenario? \n\n5. Discuss the role that dynamic planning and closed loop optimization can play in your decision analysis. \n\nPlease submit your lab report to me as a pdf. Please include a link to your GitHub repository. \n\n---\njupyter:\n  kernelspec:\n    display_name: engs199\n    language: python\n    name: engs199\n    path: /Users/f006dwr/Library/Jupyter/kernels/engs199\n  language_info:\n    codemirror_mode:\n      name: ipython\n      version: 3\n    file_extension: .py\n    mimetype: text/x-python\n    name: python\n    nbconvert_exporter: python\n    pygments_lexer: ipython3\n    version: 3.13.3\n---\n",
    "supporting": [
      "lab06-dps_files/figure-ipynb"
    ],
    "filters": []
  }
}